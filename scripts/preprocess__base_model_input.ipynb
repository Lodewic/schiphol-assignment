{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create minimal model input\n",
    "\n",
    "- Takes the flights data\n",
    "- Processes the schedule/realized datetimes and computes the delay in seconds\n",
    "- Remove observations with unknown prediction targets\n",
    "- Write prediction target with minimal feature set to CSV\n",
    "\n",
    "### Parameters\n",
    "\n",
    "-------------------\n",
    "- `input_file`: Filepath of flights data in format received from Schiphol\n",
    "- `output_file`: Filepath to write output csv file with minimal modelling input\n",
    "\n",
    "\n",
    "### Returns\n",
    "\n",
    "-----------------\n",
    "\n",
    "Output CSV file written to `output_file` with minimal model input\n",
    "\n",
    "Example output,\n",
    "    \n",
    "    id                   |  aircraftRegistration  |  airlineCode  |  terminal  |  serviceType  |      scheduleDateTime        |     actualOffBlockTime      |  scheduleDelaySeconds\n",
    "    124257473326719795   |    PHEXI               |     80.0      |     2.0    |       J       |  2018-05-01 16:35:00+02:00   |  2018-05-01 16:58:16+02:00  |         1396.0\n",
    "    124538476600837715   |    PHEXL               |     2481.0    |     1.0    |       J       |  2018-06-10 13:00:00+02:00   |  2018-06-10 13:11:25+02:00  |         685.0\n",
    "    123512829091050355   |    PHBQO               |     100.0     |     2.0    |       J       |  2018-01-15 10:15:00+01:00   |  2018-01-15 10:35:10+01:00  |         1210.0\n",
    "    123786805997701057   |    PHEXG               |     2481.0    |     1.0    |       J       |  2018-02-23 17:45:00+01:00   |  2018-02-23 17:55:52+01:00  |         652.0\n",
    "    124664922607744671   |    PHBXP               |     1551.0    |     2.0    |       J       |  2018-06-28 20:50:00+02:00   |  2018-06-28 22:09:23+02:00  |         4763.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# input parameters cell\n",
    "input_file = \"../lvt-schiphol-assignment-snakemake/data/raw/flights.csv\"\n",
    "output_file = \"processed_flights.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.data.google_storage_io import read_csv_data, write_csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_percentages(df):\n",
    "    \"\"\"Calculate summary of missing values per column\"\"\"\n",
    "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "    missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                     'percent_missing': percent_missing})\n",
    "\n",
    "    missing_value_df = missing_value_df.sort_values('percent_missing', ascending=False)\n",
    "    return missing_value_df\n",
    "\n",
    "\n",
    "def check_col_singular(x):\n",
    "    \"\"\"check if pd.Series contains more than 1 unique value excluding NaN\"\"\"\n",
    "    return x.dropna().nunique() <= 1\n",
    "\n",
    "\n",
    "def drop_singular_columns(df, verbose=False):\n",
    "    \"\"\"Drop DataFrame columns with 1 or fewer unique values excluding NaN\"\"\"\n",
    "    col_singular = df.apply(check_col_singular, axis=0)\n",
    "    if verbose:\n",
    "        n_singular = sum(col_singular)\n",
    "        print(f\"Dropping {n_singular} columns\")\n",
    "        print(f\"{col_singular[col_singular].index}\")\n",
    "        \n",
    "    df_output = df[[col for col, is_singular in col_singular.items() \n",
    "                    if not is_singular]]\n",
    "    return df_output\n",
    "\n",
    "\n",
    "def clean_flights(df_flights, verbose=True):\n",
    "    \"\"\"Clean flights data by removing singular columns and formatting dates\"\"\"\n",
    "    df = df_flights\n",
    "    df = df.dropna(subset=[\"scheduleDate\", \"scheduleTime\", \"actualOffBlockTime\"]).reset_index()\n",
    "    \n",
    "    # remove singular columns\n",
    "    df = drop_singular_columns(df, verbose=verbose)\n",
    "    \n",
    "    # format datetime fields\n",
    "    df[\"actualOffBlockTime\"] = pd.to_datetime(df[\"actualOffBlockTime\"], utc=True).dt.tz_convert('Europe/Amsterdam')\n",
    "    \n",
    "    series_datetime_str = df['scheduleDate'].astype(str) + \" \" + df['scheduleTime'].astype(str)\n",
    "    df[\"scheduleDateTime\"] = pd.to_datetime(series_datetime_str, format=\"%Y%m%d %H:%M:%S\").dt.tz_localize('Europe/Amsterdam')\n",
    "    \n",
    "#     calculate delay as difference between scheduled and realized departure\n",
    "    df[\"scheduleDelaySeconds\"] = pd.to_timedelta(df[\"actualOffBlockTime\"] - df[\"scheduleDateTime\"]).dt.total_seconds()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_flights_data(filename):\n",
    "    \"\"\"Read data local or from Google Storage bucket and clean it\"\"\"\n",
    "    df = read_csv_data(input_file)\n",
    "    print(f\"Loaded data from: {input_file}\\n\"\n",
    "          f\"Shape of data: {df.shape}\")\n",
    "    \n",
    "    df = clean_flights(df)\n",
    "    print(f\"Cleaned flights data\\n\"\n",
    "          f\"Shape of data: {df.shape}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file from local directory\n",
      "File:\t../lvt-schiphol-assignment-snakemake/data/raw/flights.csv\n",
      "\n",
      "Wall time: 1.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = read_csv_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523275, 28), (512204,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df[\"id\"].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22106, 28), (11035, 28))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"id\"].isin(df[\"id\"][df[[\"id\"]].duplicated()].unique())].shape, df[df[\"id\"].isin(df[\"id\"][df[[\"id\"]].duplicated()].unique())].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df[\"id\"].isin(df[\"id\"][df[[\"id\"]].duplicated()].unique())].drop_duplicates()\n",
    "df2[[\"id\"]].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"id\"].isin(df[\"id\"][df[[\"id\"]].duplicated()].unique())].sort_values(\"id\").drop_duplicates().to_csv(\"dupl.ipynb_checkpoints/cates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output prediction target.ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'actualOffBlockTime', 'aircraftRegistration',\n",
       "       'aircraftType.iatamain', 'aircraftType.iatasub', 'airlineCode',\n",
       "       'expectedTimeBoarding', 'expectedTimeGateClosing',\n",
       "       'expectedTimeGateOpen', 'flightName', 'flightNumber', 'gate', 'id',\n",
       "       'mainFlight', 'prefixIATA', 'prefixICAO', 'publicEstimatedOffBlockTime',\n",
       "       'publicFlightState.flightStates', 'route.destinations', 'scheduleDate',\n",
       "       'scheduleTime', 'serviceType', 'terminal',\n",
       "       'transferPositions.transferPositions', 'scheduleDateTime',\n",
       "       'scheduleDelaySeconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>aircraftRegistration</th>\n",
       "      <th>airlineCode</th>\n",
       "      <th>terminal</th>\n",
       "      <th>serviceType</th>\n",
       "      <th>scheduleDateTime</th>\n",
       "      <th>actualOffBlockTime</th>\n",
       "      <th>scheduleDelaySeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123414481790510775</td>\n",
       "      <td>PHPXB</td>\n",
       "      <td>148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 03:30:00+01:00</td>\n",
       "      <td>2018-01-01 03:22:00+01:00</td>\n",
       "      <td>-480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123414479288269149</td>\n",
       "      <td>PHHSJ</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-01-01 06:00:00+01:00</td>\n",
       "      <td>2018-01-01 05:58:22+01:00</td>\n",
       "      <td>-98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123414479666542945</td>\n",
       "      <td>PHHSG</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-01-01 06:05:00+01:00</td>\n",
       "      <td>2018-01-01 06:00:00+01:00</td>\n",
       "      <td>-300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123414479288365061</td>\n",
       "      <td>PHHSG</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-01-01 06:05:00+01:00</td>\n",
       "      <td>2018-01-01 06:00:00+01:00</td>\n",
       "      <td>-300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123414479288274329</td>\n",
       "      <td>PHHXB</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>J</td>\n",
       "      <td>2018-01-01 06:15:00+01:00</td>\n",
       "      <td>2018-01-01 06:26:34+01:00</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id aircraftRegistration  airlineCode  terminal serviceType  \\\n",
       "0  123414481790510775                PHPXB        148.0       NaN         NaN   \n",
       "1  123414479288269149                PHHSJ        164.0       1.0           J   \n",
       "2  123414479666542945                PHHSG        100.0       1.0           J   \n",
       "3  123414479288365061                PHHSG        164.0       1.0           J   \n",
       "4  123414479288274329                PHHXB        164.0       1.0           J   \n",
       "\n",
       "           scheduleDateTime        actualOffBlockTime  scheduleDelaySeconds  \n",
       "0 2018-01-01 03:30:00+01:00 2018-01-01 03:22:00+01:00                -480.0  \n",
       "1 2018-01-01 06:00:00+01:00 2018-01-01 05:58:22+01:00                 -98.0  \n",
       "2 2018-01-01 06:05:00+01:00 2018-01-01 06:00:00+01:00                -300.0  \n",
       "3 2018-01-01 06:05:00+01:00 2018-01-01 06:00:00+01:00                -300.0  \n",
       "4 2018-01-01 06:15:00+01:00 2018-01-01 06:26:34+01:00                 694.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta columns for utility for columns we will often merge by\n",
    "output_columns = [\"id\", \"aircraftRegistration\", \"airlineCode\", \"terminal\", \n",
    "                  \"serviceType\", \"scheduleDateTime\", \"actualOffBlockTime\", \"scheduleDelaySeconds\"]\n",
    "\n",
    "# DataFrame with id + merging columns + prediction target\n",
    "df_target = df[output_columns]\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output to CSV\n",
    "\n",
    "Local or Google Storage is both handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file to local directory\n",
      "File:\tprocessed_flights.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# write output file\n",
    "write_csv_data(df_target, output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 487716 entries, 0 to 487715\n",
      "Data columns (total 8 columns):\n",
      "id                      487716 non-null int64\n",
      "aircraftRegistration    487713 non-null object\n",
      "airlineCode             486503 non-null float64\n",
      "terminal                477391 non-null float64\n",
      "serviceType             482937 non-null object\n",
      "scheduleDateTime        487716 non-null datetime64[ns, Europe/Amsterdam]\n",
      "actualOffBlockTime      487716 non-null datetime64[ns, Europe/Amsterdam]\n",
      "scheduleDelaySeconds    487716 non-null float64\n",
      "dtypes: datetime64[ns, Europe/Amsterdam](2), float64(3), int64(1), object(2)\n",
      "memory usage: 29.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_target.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:schiphol-py]",
   "language": "python",
   "name": "conda-env-schiphol-py-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
