{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge base input and feature data\n",
    "\n",
    "- Takes the flights data\n",
    "- Processes the schedule/realized datetimes and computes the delay in seconds\n",
    "- Remove observations with unknown prediction targets\n",
    "- Write prediction target with minimal feature set to CSV\n",
    "\n",
    "### Parameters\n",
    "\n",
    "-------------------\n",
    "- `base_file`: Filepath of base model input with at least column 'id'\n",
    "- `features`: List of feature files or a string of feature files separated by a '+'\n",
    "\n",
    "\n",
    "### Returns\n",
    "\n",
    "-----------------\n",
    "\n",
    "Output CSV file  with minimal model input\n",
    "\n",
    "\n",
    "          id             |  aircraftRegistration   |  airlineCode   |  terminal   |  ...   |  year   | ...\n",
    "    123414481790510775   |         PHPXB           |     148.0     |     NaN      | ...    |  2018   | ...\n",
    "    123414479288269149   |         PHHSJ           |     164.0     |     1.0      | ...    |  2018   | ...\n",
    "    123414479666542945   |         PHHSG           |     100.0     |     1.0      | ...    |  2018   | ...\n",
    "    123414479288365061   |         PHHSG           |     164.0     |     1.0      | ...    |  2018   | ...\n",
    "    123414479288274329   |         PHHXB           |     164.0     |     1.0      | ...    |  2018   | ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# input parameters cell\n",
    "base_file = \"../lvt-schiphol-assignment-snakemake/data/model_input/delays_base_input.csv\"\n",
    "features = [\n",
    "    \"../lvt-schiphol-assignment-snakemake/data/model_input/features/route_destinations.csv\",\n",
    "    \"../lvt-schiphol-assignment-snakemake/data/model_input/features/schedule_time_features.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "output_file = \"../lvt-schiphol-assignment-snakemake/data/model_input/delays_extended_input.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(features, str):\n",
    "    features = features.split('+')\n",
    "    print(\"Parsed features from string instead of List object\")\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_ignore = [\n",
    "    \"scheduleDateTime\", \"scheduleDate\", \"scheduleTime\", \"actualOffBlockTime\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.data.google_storage_io import read_csv_data, write_csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_base = read_csv_data(base_file)\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# read feature data from multiple files and merge by 'id'\n",
    "print(f\"Reading features from first file: {features[0]}\")\n",
    "df_features = read_csv_data(features[0])\n",
    "\n",
    "if len(features) > 0:\n",
    "    for feature_file in features[1:]:\n",
    "        print(f\"Merging features from file: {feature_file}\")\n",
    "        old_shape = df_features.shape\n",
    "        tmp_features = read_csv_data(feature_file)\n",
    "        df_features = pd.merge(\n",
    "            df_features,\n",
    "            tmp_features,\n",
    "            on=\"id\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        print(f\"Merged features. Shape {old_shape} -> {df_features.shape}\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge base model input with features\n",
    "\n",
    "- One large file to pass onto model notebooks\n",
    "\n",
    "Downside: One large file with a lot of copied values\n",
    "\n",
    "Upside: Easier to verify downstream model notebooks use the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.merge(\n",
    "    df_base,\n",
    "    df_features,\n",
    "    on=\"id\",\n",
    "    how=\"inner\")\n",
    "print(f\"Data shape: {df_output.shape}\")\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output to CSV\n",
    "\n",
    "Local or Google Storage is both handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write output file\n",
    "write_csv_data(df_output, output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# aircraft_flight_counts = Counter(df_model_input[\"aircraftRegistration\"])\n",
    "# import seaborn as sns\n",
    "# sns.distplot(list(aircraft_flight_counts.values()))\n",
    "# plt.show()\n",
    "\n",
    "# df_aircraft_groups = df_model_input.groupby(\"aircraftRegistration\")\n",
    "# for group, group_data in list(df_aircraft_groups):\n",
    "#     if aircraft_flight_counts[group] > 1000:\n",
    "#         group_data.plot(x='scheduleDateTime', y='scheduleDelaySeconds')\n",
    "#         plt.show()\n",
    "\n",
    "# # df_aircraft_groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:schiphol-py]",
   "language": "python",
   "name": "conda-env-schiphol-py-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
